---
title: "Tutorial cognitivemapr based on paper join sessions"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tutorial cognitivemapr based on paper join sessions}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

This article will introduce the method of Cognitive Mapping (CM) as well
as the Rpackage cognitivemapr (still under development) that will reduce
the initial investment needed to start using the method. CM is a method
specifically designed to study belief systems as espoused by individuals
or organisations and has several advantages over other methods.It starts
from the premise that belief systems are best conceived as semantic
networks consisting of causal and normative relations between ideas
(Axelrod 1976; Young 1996; Yang and González-Bailón 2017). Using
visualisation techniques as well as graph theory, CM fosters a more in
depth understanding of beliefs than other methods as it helps reveal the
argumentation underlying belief systems, makes it possible to
distinguish amongst different types of beliefs (core versus peripherical
beliefs, instrumental versus paradigmatic beliefs) as well as establish
the saliency of beliefs and argumentations (Van Esch and Snellens online
first). Moreover, it allows scholars to study the belief systems of
political actors in both a qualitative and quantitative, deductive and
inductive manner. Finally, the CM technique can be used to study beliefs
embedded in texts or speech acts as well as be used as a survey tool. It
is therefore suitable to study the beliefs of political actors and
citizens in an indirect way (at-a-distance) or by querying respondents
directly (Van Esch, Joosen, and Van Zuydam 2016). To illustrate the
various ways in which the technique of Cognitive Mapping may be used,
the paper will draw upon a database of cognitive maps of **European
political and financial leaders and citizens from nine EU member states
regarding the Eurozone crisis.**

# Cognitive Mapping

Cognitive mapping offers scholars a standardised way of studying ideas
and has been successfully applied in the fields of political and social
psychology, communication and organizational sciences and economics
(Axelrod 1976; Bougon, Weick, and Binkhorst 1977; Boukes et al. 2020;
Laukkanen and Wang 2016; Van Esch 2012). The CM technique rests upon the
premise that ideas are reflected in spoken or written communication like
speech acts, institutional documents, media sources and interviews.
Moreover, the technique has also been used as a tool to elicit the
beliefs of individuals directly during interviews or in survey settings.
Finally, the method has been used in the context of focus groups to
elicit, study or stimulate the development of collective belief systems
(Boukes et al; Van Esch, Joosen, and Van Zuydam 2016; Curseu et al
2010). Whereas other techniques to derive ideas from text use concepts
or themes as their unit of analysis, the basis of a cognitive map is the
relationship between the concepts (Axelrod 1976). More specifically, to
create a cognitive map all the causal and utility relationships between
concepts are derived from a text or elicited from respondents. Utility
relations are statements to the effect that concept x is 'good', 'in
someone's interest' or 'in the general benefit'. Conducting a CM
analysis thus reveals actors' arguments (a leads to b) as well as their
normative evaluations (b is a worthy cause / beneficial), and as such
provides an in-depth analysis of the beliefs and underlying
argumentation embedded in texts or speech acts. In contrast to other
qualitative text analyses, the annotation of texts or direct elicitation
of responses for the CM technique is generic in the sense that it is
conducted in the same manner regardless of the topic at hand. For the CM
as a text-analysis method, detailed coding-manuals exist, and earlier
studies indicate that scholars need relatively little training to
achieve good rates of inter-coder reliability (Axelrod 1976; Hart 1977;
Young and Schafer 1998). In addition, scholars have also researched and
discussed best practices when using the direct elicitation form of CM
analysis and do's and don't when integrating the method in a survey
(refs). The method therefore forms a reliable alternative to other
methods used to study ideas and beliefs, and due to its generic and
structured nature may facilitate comparison across studies and knowledge
accumulation. Another added value of cognitive mapping is that the
relationships between concepts represented in a CM may be analysed in a
qualitative and quantitative manner, making the technique useful for a
wide variety of research questions. To facilitate the coding and
analysis of cognitive maps various tool and applications are available,
but requires a steep learning curve and initial investment (Bastian,
Heymann, and Jacomy 2009; Young 1996). The newly developed R-package
cognitivemapr bundles visual, qualitative and quantitative modes of
analyses.

Install cognitivemapr:

```{r, results='hide', warning=FALSE, message=FALSE}
install.packages("devtools", repos = "https://cloud.r-project.org/")
library(devtools)

devtools::install_github("https://github.com/Fesch-star/cognitivemapr")
```

## Gathering the data

As indicated above, cognitive map data may be obtained in two ways:
Through indirect elicitation throught the analysis of texts or
speech-acts or by direct elicitation of the data from respondents
through a survey or focus groups. The first method is common for studies
that focus on political elite, whereas the second is mostly used when
scholars are interested in the beliefs of the public of members of an
organisation.

The indirect method of eliciting CM data rests upon the premise that
ideas are reflected in spoken or written communication like speech acts,
institutional documents, media sources and interviews. Whereas other
techniques to derive ideas from text use concepts or themes as their
unit of analysis, the basis of a cognitive map is the relationship
between the concepts (Axelrod, 1976). More specifically, to create a
cognitive map all the causal and utility relationships between concepts
are derived from a text. Utility relations are statements to the effect
that concept x is 'good', 'in someone's interest' or 'in the general
benefit'. Larger (sets of) maps may benefit from a certain level of
standardisation of concepts once all relations are derived. Detailed
coding-manuals exist to guide the coding process, and earlier studies
indicate that scholars need relatively little training to achieve good
rates of intercoder reliability (Axelrod, 1976; Hart, 1977; Young &
Schafer, 1998). While some attempts have been made to automate the CM
indirect coding process (Van Esch et al 2022; Young 1992), no viable
automated scheme is available yet.

In the case of indirect elicitation of a cognitive map, two different
procedures are available: the pairwise comparison and freehand drawing
approach. The pairwise comparison presents actors' (leaders or citizens)
with a set of concepts and asks them to evaluate whether pairs of
concepts are causally or normatively related or not. Participants to the
research will have to review all possible combinations of the concepts
in the set (Hodgkinson et al 2004; Clarkson & Hodgkinson 2005; Markiczy
& Goldberg 1995). Previous studies suggest that this method results in
very comprehensive maps, but the method is also more time-consuming and
labour intensive and is seen to be tedious by participants. In addition,
Hodgkinson et all (2004) have found that participants in their study
rate representativeness of the resulting maps as much lower than of
those resulting from the freehand approach. With the freehand approach,
respondents start by choosing concepts they deem most relevant for the
topic at hand (from a predetermined list, or inductively) and
graphically draw arrows between these concepts to represent their ideas
on how these concepts relate. Participants draw different types of
arrows to represent negative or positive relationships between concepts.
This results in a cognitive map that reflects the ideas of the
respondents directly.[^1]

[^1]: In order to allow the participant to draw maps directly, the
    authors developed aweb-based application was developed, DART. This
    software allows respondents to draw their personal map freehand
    through a user-friendly digital interface and automatically creates
    a digital database of cognitive maps. The data from these maps can
    be linked to the outcomes of survey questions about political and
    demographic characteristics of respondents, and allows for the
    aggregation, processing and analysis of data from large groups of
    citizens. Finally, DART exports the survey and CM data in the
    formats required by other analytical (CM) software packages like
    SPSS, Worldview and Gephi (Bastian et al 2009; Young 1996).

To analyse this data, various quantitative measures are used. Moreover,
to facilitate qualitative or narrative analysis, the data is often
transformed into a visual graph - the cognitive map - in which the
derived concepts are depicted as points and the relations between these
concepts as arrows (Axelrod 1976; Young 1996; Young and Schafer 1998,
see **figure** **1**). Various tool and applications are available to
analyse cognitive maps, but few offer an open-source full workflow or
produce CMs that can readily be used for qualitative analysis, several
also require a steep learning curve (Bastian, Heymann, and Jacomy 2009;
Young 1996). By developing the R-package cognitivemapr, we hope to
bundle visual, qualitative and quantitative modes of analyses to lower
the threshold for scholars to start using cognitive maps in their
research.

## Preparing the data

The cognitivemapr package requires you to compile your CM data into two
csv.files with several mandatory variables included. In addition the
exact order of the mandatory columns should be maintained (except for
the value.x and value.y in the edgelist).

1.  An edgelist with all the relations in a cognitive map, with the
    following mandatory columns:

    -   "from": containing the id of "cause"-concept

    -   "to": containing the id of the "effect"-concept

    -   "edge_value": whether the relation is positive, negative or
        non-existent

    -   "weight": the number of times the (exact same) relation appears
        in your data

    -   "value.x": the value of the cause ('from') concept: -1 =
        negative, 0 = ambiguous, 1 = positive (see nodelist)

    -   "value.y": the value of the effect ('to') concept: -1 =
        negative, 0 = ambiguous, 1 = positive (see nodelist)

2.  A nodelist with all the unique concepts a cogntive map, with the
    following mandatory columns:

    -   "id": the id of the concept

    -   "value": whether the concept is inherently negative (-1),
        positive (1) or ambiguous (0)[^2]
        
***ADD INSTRUCTION ON HOW TO PREP DATA FOR PARADIGM & CATEGORY CALCS***

[^2]: This should be consistent to the values (value.x / value.y) in the
    edgelist. We would advise to be reticent in assigning concepts a
    negative pr ambiguous value when working with a set of maps
    especially when these involve different actors as the concept will
    be seen as see to be inherently negative/ambiguous by all actors.
    Moreover, one of the strengths of the CM analysis is that it offers
    ways to derive the value of concepts per CM (see section on
    Evaluation below).

On top of these mandatory variables, you may want to add additional
information like meta-data (name of actor, date), the name of the
concepts or some kind of categorisation of the concepts for practical or
theoretical reasons. In this paper, we will use data concerning the
beliefs of the Dutch prime minister Mark Rutte regarding the Eurozone
crisis as an example. You can download this data from Github by running
the following code:

```{r, results='hide', warning=FALSE, message=FALSE}
#base::library(readr)

load("../data/rutte_p2_edgelist.rda")
load("../data/rutte_p2_nodelist.rda")


```


The top 6 rows of both the edgelist and nodelist are shown below. In
addition to the mandatory columns, it shows the metadata that was
included in the edgelist. Moreover, the head of the nodelist indicates
that we also added the concept names (node_name) to facilitate
qualitative analysis and categorised the concepts in terms of economic
paradigma (eco), type of integration (int) and type of policy instrument
(instr) to conduct some theoretically interesting analyses on the data
later on in this paper (see section on categorisation below).[^3]

[^3]: See Van Esch and Snellens first online for the theoretical
    background of these categorisations.

```{r}
head(rutte_p2_edgelist)
head(rutte_p2_nodelist)
```

## Calculating basic CM measures

There are various ways of analysing CM data contained in the edge and
nodelist. While the full potential of the method lies in transforming
the causal and utility relations derived from text or respondents into a
graph, we will start by calculating some basic quantitative
measures.[^4]

[^4]: As is shown in the calc_degree_goW function below, the calculation
    of these measures actually do require you to transform the edge and
    nodelist into a CM/graph (by using the 'graph_from_data_frame'
    function from the package igraph). However, as a lot more is
    involved to derive a visual CM that can be analysed qualitatively
    and some of the basic quantitative measures can help enhance the
    depth of information included in such visualization (see
    visualisation section below), we will start with the basic
    quantitative measures.

The basis for the analysis of CM data are the weight of relations and
the centrality (C) and saliency (S) of the concepts. The 'weight' of a
relation is determined by how many times an actor refers to the relation
in their texts or speech-acts and is included in the original edgelist
(see the column 3 in the edgelist above). The 'centrality' of a concept
is determined by establishing the number of connections of a concept
with other concepts in the map while the measure 'saliency' denotes the
number of connection of a concept with other concepts, but also takes
the weight of the relations into account. Whereas centrality is used in
CM analysis as a basic measure for the complexity of ideas, the weight
and saliency are indicators of how strong a particular belief is. As
complexity and strength are regarded as consequential for the effect of
ideas and beliefs on political behaviour and policy-making, these
measures may help answer important research questions in the field. In
addition, on the basis of how many relations feed into a concept
(indegree or the weighted variant weighted indegree) and how many
relations feed out from a concept (outdegree or the weighted variant
weighted outdegree), the measure 'goal-orientation (go)' (or its
weighted variant, gow) can be calculated. This measure provides an
indication of the extent to which a concept is seen as a cause (go(w) =
-1) or an effect (go(w) = 1) in the CM that is being analysed.

To calculate these basic measures, the cognitivemapr package uses
functions from the igraph packages. Although this works well, the igraph
package uses different terms for several of the measures (see table
**x** below).

| CM term    | Meaning                                                       | Synonym         |
|------------|---------------------------------------------------------------|-----------------|
| Concept    | Cause or effect (raw or standardised                          | Node            |
| Relation   | Causal or utility relation                                    | Edge            |
| CM         | Visual graph showing concepts and relations                   | Map             |
| Centrality | Number of connections of a concept to other concepts          | Degree          |
| Saliency   | Weighted number of connections of a concept to other concepts | Weighted degree |

In order to calculate all the basic measures in one go and store them
into a dataframe and combine them with the original information on the
concepts, we created the following function 'calc_degrees_goW'.

```{r, message=FALSE, warning=FALSE}
base::library(igraph)
base::library(dplyr)

#Creating a function to do the basic CM calculations and store them in a dataframe
calc_degrees_goW <- function(edgelist, nodelist) {

#transform edge & nodelist into a map
  map <- graph_from_data_frame(d = edgelist, vertices = nodelist, directed = TRUE)

#calculate for each node
  deg <- degree(map, mode = "all") #degrees (centrality in CM speech)
  indeg <- degree(map, mode = "in") #indegrees
  outdeg <- degree(map, mode = "out") #outdegrees
  w_indeg <- strength(map, mode = "in") #weighted indegrees 
  w_outdeg <- strength(map, mode = "out") #weighted outdegrees
  w_deg <- strength(map, mode = "all") #weighted degrees (saliency in CM speech)
  
#make new df to store the calculated values
  node_calc <- nodelist

#link vectors with all the (weighted) degrees values to 
#the new node_calc df as columns
  node_calc$indegree <- indeg
  node_calc$outdegree <- outdeg
  node_calc$degree <- deg
  node_calc$w_indegree <- w_indeg
  node_calc$w_outdegree <- w_outdeg
  node_calc$w_degree <- w_deg
  
#calculates go & goW and link it to the df node_calc as columns
  node_calc <- mutate(node_calc, 
          go = (node_calc$indegree - node_calc$outdegree) / node_calc$degree,
          gow = (node_calc$w_indegree - node_calc$w_outdegree) / node_calc$w_degree)
  return(node_calc) #returns the df node_calc with all calculated values
}

```

Running this function using the data of Rutte shows that the function
returns a dataframe in which all the original data on the nodes in the
CM is combined with the basic measures. Running the summary shows some
basic characterising and statistical information regarding the variables
in the dataframe. This provides some first indication regarding the
number of concepts in the CM, the difference in strenght of the concepts
in the map (minimum, maximum, mean w_degree) as well as the overall
complexity of the map (mean degree) that may help compare the CM to
others.

```{r}
#running the function with the data of Mark Rutte, and storing it as a df
rutte_p2_node_calc <- calc_degrees_goW(rutte_p2_edgelist, rutte_p2_nodelist)

#provide summary statistics for all measures
summary(rutte_p2_node_calc)

```

In addition, the sum of saliency tells us of how many relations the CM
consists, which is the most commonly used measure of the relative size
of a CM in comparison to others.[^5]

[^5]: The sum of the saliency of all concepts is always twice the amount
    of relations in a CM, as saliency counts both 'sides' of the
    relationship: the weighted indegree and weighted outdegree. When
    used consistently as a measure of map-size dividing it by two is
    superfluous.

```{r}
#Sum of w_degree provides a first indication of the size of the CM 
sum(rutte_p2_node_calc$w_degree)

```

At the concept level, the output of the calc_degrees_goW function also
provides us with the first feel of the content of the CM. The table
below, for instance shows the top 10 concepts in terms of saliency and
economic paradigm (ordoliberal or keynesian) for the map of Rutte. The
table provides a first indication that the Dutch prime minister was
highly concerned about the Eurozone crisis, and was discussing several
institutional and predominantly ordoliberal measures to tackle the
crisis, while also debating the value of being pragmatic.
