[{"path":"/articles/paper-joint-sessions-vignette.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Tutorial cognitivemapr based on paper join sessions","text":"article introduce method Cognitive Mapping (CM) well Rpackage cognitivemapr (still development) reduce initial investment needed start using method. CM method specifically designed study belief systems espoused individuals organisations several advantages methods.starts premise belief systems best conceived semantic networks consisting causal normative relations ideas (Axelrod 1976; Young 1996; Yang González-Bailón 2017). Using visualisation techniques well graph theory, CM fosters depth understanding beliefs methods helps reveal argumentation underlying belief systems, makes possible distinguish amongst different types beliefs (core versus peripherical beliefs, instrumental versus paradigmatic beliefs) well establish saliency beliefs argumentations (Van Esch Snellens online first). Moreover, allows scholars study belief systems political actors qualitative quantitative, deductive inductive manner. Finally, CM technique can used study beliefs embedded texts speech acts well used survey tool. therefore suitable study beliefs political actors citizens indirect way (--distance) querying respondents directly (Van Esch, Joosen, Van Zuydam 2016). illustrate various ways technique Cognitive Mapping may used, paper draw upon database cognitive maps European political financial leaders citizens nine EU member states regarding Eurozone crisis.","code":""},{"path":"/articles/paper-joint-sessions-vignette.html","id":"cognitive-mapping","dir":"Articles","previous_headings":"","what":"Cognitive Mapping","title":"Tutorial cognitivemapr based on paper join sessions","text":"Cognitive mapping offers scholars standardised way studying ideas successfully applied fields political social psychology, communication organizational sciences economics (Axelrod 1976; Bougon, Weick, Binkhorst 1977; Boukes et al. 2020; Laukkanen Wang 2016; Van Esch 2012). CM technique rests upon premise ideas reflected spoken written communication like speech acts, institutional documents, media sources interviews. Moreover, technique also used tool elicit beliefs individuals directly interviews survey settings. Finally, method used context focus groups elicit, study stimulate development collective belief systems (Boukes et al; Van Esch, Joosen, Van Zuydam 2016; Curseu et al 2010). Whereas techniques derive ideas text use concepts themes unit analysis, basis cognitive map relationship concepts (Axelrod 1976). specifically, create cognitive map causal utility relationships concepts derived text elicited respondents. Utility relations statements effect concept x ‘good’, ‘someone’s interest’ ‘general benefit’. Conducting CM analysis thus reveals actors’ arguments (leads b) well normative evaluations (b worthy cause / beneficial), provides -depth analysis beliefs underlying argumentation embedded texts speech acts. contrast qualitative text analyses, annotation texts direct elicitation responses CM technique generic sense conducted manner regardless topic hand. CM text-analysis method, detailed coding-manuals exist, earlier studies indicate scholars need relatively little training achieve good rates inter-coder reliability (Axelrod 1976; Hart 1977; Young Schafer 1998). addition, scholars also researched discussed best practices using direct elicitation form CM analysis ’s don’t integrating method survey (refs). method therefore forms reliable alternative methods used study ideas beliefs, due generic structured nature may facilitate comparison across studies knowledge accumulation. Another added value cognitive mapping relationships concepts represented CM may analysed qualitative quantitative manner, making technique useful wide variety research questions. facilitate coding analysis cognitive maps various tool applications available, requires steep learning curve initial investment (Bastian, Heymann, Jacomy 2009; Young 1996). newly developed R-package cognitivemapr bundles visual, qualitative quantitative modes analyses. Install cognitivemapr:","code":"install.packages(\"devtools\", repos = \"https://cloud.r-project.org/\") library(devtools)  devtools::install_github(\"https://github.com/Fesch-star/cognitivemapr\")"},{"path":"/articles/paper-joint-sessions-vignette.html","id":"gathering-the-data","dir":"Articles","previous_headings":"Cognitive Mapping","what":"Gathering the data","title":"Tutorial cognitivemapr based on paper join sessions","text":"indicated , cognitive map data may obtained two ways: indirect elicitation throught analysis texts speech-acts direct elicitation data respondents survey focus groups. first method common studies focus political elite, whereas second mostly used scholars interested beliefs public members organisation. indirect method eliciting CM data rests upon premise ideas reflected spoken written communication like speech acts, institutional documents, media sources interviews. Whereas techniques derive ideas text use concepts themes unit analysis, basis cognitive map relationship concepts (Axelrod, 1976). specifically, create cognitive map causal utility relationships concepts derived text. Utility relations statements effect concept x ‘good’, ‘someone’s interest’ ‘general benefit’. Larger (sets ) maps may benefit certain level standardisation concepts relations derived. Detailed coding-manuals exist guide coding process, earlier studies indicate scholars need relatively little training achieve good rates intercoder reliability (Axelrod, 1976; Hart, 1977; Young & Schafer, 1998). attempts made automate CM indirect coding process (Van Esch et al 2022; Young 1992), viable automated scheme available yet. case indirect elicitation cognitive map, two different procedures available: pairwise comparison freehand drawing approach. pairwise comparison presents actors’ (leaders citizens) set concepts asks evaluate whether pairs concepts causally normatively related . Participants research review possible combinations concepts set (Hodgkinson et al 2004; Clarkson & Hodgkinson 2005; Markiczy & Goldberg 1995). Previous studies suggest method results comprehensive maps, method also time-consuming labour intensive seen tedious participants. addition, Hodgkinson et (2004) found participants study rate representativeness resulting maps much lower resulting freehand approach. freehand approach, respondents start choosing concepts deem relevant topic hand (predetermined list, inductively) graphically draw arrows concepts represent ideas concepts relate. Participants draw different types arrows represent negative positive relationships concepts. results cognitive map reflects ideas respondents directly.1 analyse data, various quantitative measures used. Moreover, facilitate qualitative narrative analysis, data often transformed visual graph - cognitive map - derived concepts depicted points relations concepts arrows (Axelrod 1976; Young 1996; Young Schafer 1998, see figure 1). Various tool applications available analyse cognitive maps, offer open-source full workflow produce CMs can readily used qualitative analysis, several also require steep learning curve (Bastian, Heymann, Jacomy 2009; Young 1996). developing R-package cognitivemapr, hope bundle visual, qualitative quantitative modes analyses lower threshold scholars start using cognitive maps research.","code":""},{"path":"/articles/paper-joint-sessions-vignette.html","id":"preparing-the-data","dir":"Articles","previous_headings":"Cognitive Mapping","what":"Preparing the data","title":"Tutorial cognitivemapr based on paper join sessions","text":"cognitivemapr package requires compile CM data two csv.files several mandatory variables included. addition exact order mandatory columns maintained (except value.x value.y edgelist). edgelist relations cognitive map, following mandatory columns: “”: containing id “cause”-concept “”: containing id “effect”-concept “edge_value”: whether relation positive, negative non-existent “weight”: number times (exact ) relation appears data “value.x”: value cause (‘’) concept: -1 = negative, 0 = ambiguous, 1 = positive (see nodelist) “value.y”: value effect (‘’) concept: -1 = negative, 0 = ambiguous, 1 = positive (see nodelist) nodelist unique concepts cogntive map, following mandatory columns: “id”: id concept “value”: whether concept inherently negative (-1), positive (1) ambiguous (0)2 ADD INSTRUCTION PREP DATA PARADIGM & CATEGORY CALCS top mandatory variables, may want add additional information like meta-data (name actor, date), name concepts kind categorisation concepts practical theoretical reasons. paper, use data concerning beliefs Dutch prime minister Mark Rutte regarding Eurozone crisis example. can download data Github running following code: top 6 rows edgelist nodelist shown . addition mandatory columns, shows metadata included edgelist. Moreover, head nodelist indicates also added concept names (node_name) facilitate qualitative analysis categorised concepts terms economic paradigma (eco), type integration (int) type policy instrument (instr) conduct theoretically interesting analyses data later paper (see section categorisation ).3","code":"#base::library(readr)  load(\"../data/rutte_p2_edgelist.rda\") load(\"../data/rutte_p2_nodelist.rda\") head(rutte_p2_edgelist) ##   from to weight edge_value edge_id map_id   map_date    speaker value.x ## 1   21 39      1          1       1    383 2011-04-06 Rutte Mark       1 ## 2  294 39      1          1       2    383 2011-04-06 Rutte Mark       1 ## 3  370 39      1          1       3    383 2011-04-06 Rutte Mark       1 ## 4  380 39      1          1       4    383 2011-04-06 Rutte Mark       1 ## 5  461 39      1          1       5    383 2011-04-06 Rutte Mark       1 ## 6  562 39      1          1       6    383 2011-04-06 Rutte Mark       1 ##   value.y ## 1       1 ## 2       1 ## 3       1 ## 4       1 ## 5       1 ## 6       1 head(rutte_p2_nodelist) ##   id                  node_name   paradigms               int value ## 1  8             60% debt ratio Ordoliberal              <NA>     1 ## 2 21 Attractiveness to business        <NA>              <NA>     1 ## 3 25        Automatic sanctions Ordoliberal     Supranational     1 ## 4 39             benefit of all        <NA>              <NA>     1 ## 5 40     Benefit of debt-states        <NA> Intergovernmental     1 ## 6 48      Benefit of the people        <NA>              <NA>     1 ##                     instruments ## 1                          <NA> ## 2                          <NA> ## 3 Stronger EU fiscal regulation ## 4                          <NA> ## 5                          <NA> ## 6                          <NA>"},{"path":"/articles/paper-joint-sessions-vignette.html","id":"calculating-basic-cm-measures","dir":"Articles","previous_headings":"Cognitive Mapping","what":"Calculating basic CM measures","title":"Tutorial cognitivemapr based on paper join sessions","text":"various ways analysing CM data contained edge nodelist. full potential method lies transforming causal utility relations derived text respondents graph, start calculating basic quantitative measures.4 basis analysis CM data weight relations centrality (C) saliency (S) concepts. ‘weight’ relation determined many times actor refers relation texts speech-acts included original edgelist (see column 3 edgelist ). ‘centrality’ concept determined establishing number connections concept concepts map measure ‘saliency’ denotes number connection concept concepts, also takes weight relations account. Whereas centrality used CM analysis basic measure complexity ideas, weight saliency indicators strong particular belief . complexity strength regarded consequential effect ideas beliefs political behaviour policy-making, measures may help answer important research questions field. addition, basis many relations feed concept (indegree weighted variant weighted indegree) many relations feed concept (outdegree weighted variant weighted outdegree), measure ‘goal-orientation (go)’ (weighted variant, gow) can calculated. measure provides indication extent concept seen cause (go(w) = -1) effect (go(w) = 1) CM analysed. calculate basic measures, cognitivemapr package uses functions igraph packages. Although works well, igraph package uses different terms several measures (see table x ). order calculate basic measures one go store dataframe combine original information concepts, created following function ‘calc_degrees_goW’. Running function using data Rutte shows function returns dataframe original data nodes CM combined basic measures. Running summary shows basic characterising statistical information regarding variables dataframe. provides first indication regarding number concepts CM, difference strenght concepts map (minimum, maximum, mean w_degree) well overall complexity map (mean degree) may help compare CM others. addition, sum saliency tells us many relations CM consists, commonly used measure relative size CM comparison others.5 concept level, output calc_degrees_goW function also provides us first feel content CM. table , instance shows top 10 concepts terms saliency economic paradigm (ordoliberal keynesian) map Rutte. table provides first indication Dutch prime minister highly concerned Eurozone crisis, discussing several institutional predominantly ordoliberal measures tackle crisis, also debating value pragmatic.","code":"base::library(igraph) base::library(dplyr)  #Creating a function to do the basic CM calculations and store them in a dataframe calc_degrees_goW <- function(edgelist, nodelist) {  #transform edge & nodelist into a map   map <- graph_from_data_frame(d = edgelist, vertices = nodelist, directed = TRUE)  #calculate for each node   deg <- degree(map, mode = \"all\") #degrees (centrality in CM speech)   indeg <- degree(map, mode = \"in\") #indegrees   outdeg <- degree(map, mode = \"out\") #outdegrees   w_indeg <- strength(map, mode = \"in\") #weighted indegrees    w_outdeg <- strength(map, mode = \"out\") #weighted outdegrees   w_deg <- strength(map, mode = \"all\") #weighted degrees (saliency in CM speech)    #make new df to store the calculated values   node_calc <- nodelist  #link vectors with all the (weighted) degrees values to  #the new node_calc df as columns   node_calc$indegree <- indeg   node_calc$outdegree <- outdeg   node_calc$degree <- deg   node_calc$w_indegree <- w_indeg   node_calc$w_outdegree <- w_outdeg   node_calc$w_degree <- w_deg    #calculates go & goW and link it to the df node_calc as columns   node_calc <- mutate(node_calc,            go = (node_calc$indegree - node_calc$outdegree) / node_calc$degree,           gow = (node_calc$w_indegree - node_calc$w_outdegree) / node_calc$w_degree)   return(node_calc) #returns the df node_calc with all calculated values } #running the function with the data of Mark Rutte, and storing it as a df rutte_p2_node_calc <- calc_degrees_goW(rutte_p2_edgelist, rutte_p2_nodelist)  #provide summary statistics for all measures summary(rutte_p2_node_calc) ##        id         node_name          paradigms             int            ##  Min.   :  8.0   Length:84          Length:84          Length:84          ##  1st Qu.:198.8   Class :character   Class :character   Class :character   ##  Median :386.0   Mode  :character   Mode  :character   Mode  :character   ##  Mean   :363.7                                                            ##  3rd Qu.:555.5                                                            ##  Max.   :647.0                                                            ##      value         instruments           indegree        outdegree     ##  Min.   :-1.0000   Length:84          Min.   : 0.000   Min.   :0.000   ##  1st Qu.: 1.0000   Class :character   1st Qu.: 0.000   1st Qu.:0.000   ##  Median : 1.0000   Mode  :character   Median : 1.000   Median :1.000   ##  Mean   : 0.9524                      Mean   : 1.262   Mean   :1.262   ##  3rd Qu.: 1.0000                      3rd Qu.: 1.000   3rd Qu.:2.000   ##  Max.   : 1.0000                      Max.   :30.000   Max.   :7.000   ##      degree         w_indegree      w_outdegree       w_degree      ##  Min.   : 1.000   Min.   : 0.000   Min.   :0.000   Min.   : 1.000   ##  1st Qu.: 1.000   1st Qu.: 0.000   1st Qu.:0.000   1st Qu.: 1.000   ##  Median : 1.000   Median : 1.000   Median :1.000   Median : 2.000   ##  Mean   : 2.524   Mean   : 1.369   Mean   :1.369   Mean   : 2.738   ##  3rd Qu.: 3.000   3rd Qu.: 1.000   3rd Qu.:2.000   3rd Qu.: 3.000   ##  Max.   :30.000   Max.   :36.000   Max.   :8.000   Max.   :36.000   ##        go               gow          ##  Min.   :-1.0000   Min.   :-1.0000   ##  1st Qu.:-1.0000   1st Qu.:-1.0000   ##  Median :-0.7083   Median :-0.7639   ##  Mean   :-0.2202   Mean   :-0.2192   ##  3rd Qu.: 1.0000   3rd Qu.: 1.0000   ##  Max.   : 1.0000   Max.   : 1.0000 #Sum of w_degree provides a first indication of the size of the CM  sum(rutte_p2_node_calc$w_degree) ## [1] 230"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Femke van Esch. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"van Esch F (2023). cognitivemapr: Package (One Line, Title Case). R package version 0.0.0.9000.","code":"@Manual{,   title = {cognitivemapr: What the Package Does (One Line, Title Case)},   author = {Femke {van Esch}},   year = {2023},   note = {R package version 0.0.0.9000}, }"},{"path":"/index.html","id":"cognitivemapr","dir":"","previous_headings":"","what":"What the Package Does (One Line, Title Case)","title":"What the Package Does (One Line, Title Case)","text":"Cognitive Mapping method specifically designed study belief systems espoused individuals organisations several advantages methods. goal cognitivemapr reduce initial investment currently needed start using method.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"What the Package Does (One Line, Title Case)","text":"can install development version cognitivemapr GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"Fesch-star/cognitivemapr\")"},{"path":"/index.html","id":"dependencies","dir":"","previous_headings":"","what":"Dependencies","title":"What the Package Does (One Line, Title Case)","text":"run code need install following packages: tidyverse - built R version 4.0.5 v ggplot2 3.3.3 v purrr 0.3.4 v tibble 3.1.1 v dplyr 1.0.5 v tidyr 1.1.3 v stringr 1.4.0 v readr 1.4.0 v forcats 0.5.1 igraph - built R version 4.0.5 tidygraph ggraph","code":""},{"path":"/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"What the Package Does (One Line, Title Case)","text":"basic example shows solve common problem: special using README.Rmd instead just README.md? can include R chunks like : ’ll still need render README.Rmd regularly, keep README.md --date. devtools::build_readme() handy . also use GitHub Actions re-render README.Rmd every time push. example workflow can found : https://github.com/r-lib/actions/tree/v1/examples. can also embed plots, example:  case, don’t forget commit push resulting figure files, display GitHub CRAN.","code":"library(cognitivemapr) ## basic example code summary(cars)"},{"path":[]},{"path":[]},{"path":"/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"What the Package Does (One Line, Title Case)","text":"project licensed terms GPL-3.0 License","code":""},{"path":"/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"What the Package Does (One Line, Title Case)","text":"Please cite project follows: Van Esch, Femke .W.J., Snellens, Jeroen F.. (forthcoming). ‘‘measure’ Ideas. Introducing method cognitive mapping domain ideational policy studies’. Journal European Public Policy.","code":""},{"path":"/index.html","id":"contact","dir":"","previous_headings":"","what":"Contact","title":"What the Package Does (One Line, Title Case)","text":"Femke van Esch: F..w.j.vanEsch@uu.nl","code":""},{"path":"/reference/calculate_degrees.html","id":null,"dir":"Reference","previous_headings":"","what":"calculate_degrees — calculate_degrees","title":"calculate_degrees — calculate_degrees","text":"calculate_degrees function used analyse cognitive map (CM) data. calculates various standard CM measures. need run function first can run complicated functions package: (instrument_support, paradigm_support evaluate_concepts).","code":""},{"path":"/reference/calculate_degrees.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"calculate_degrees — calculate_degrees","text":"","code":"calculate_degrees(edgelist, nodelist)"},{"path":"/reference/calculate_degrees.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"calculate_degrees — calculate_degrees","text":"edgelist function takes edgelist (dataframe) including relations CM. data needs following column structure. last two columns include meta-data optional. research projects, types meta-data may important.   nodelist function takes nodelist (dataframe) including nodes/concepts CM data needs following column structure. columns may included containing categorization concepts terms - instance - paradigm align type policy instrument concept refers . different researchprojects, different types categorizations may relevant. addition, researchers may want add meta-data nodes:","code":"* from: the 'cause'-node/concept id (corresponding to the id in the nodeslist)     * to: the 'effect'-node/concept id (corresponding to the id in the nodeslist)     * weight: the weight of the edge/relation (the number of times the relation      is mentioned in the raw data (speech/text/survey))     * map_id#: a unique id for the source (speech/text/respondent) the CM      is derived from     * map_date#: the date of the source (speech/text/survey)the CM is derived      from * id: unique id (number) for the node/concept     * node_name: node name/concept in words     * paradigms: a set of rivaling paradigms concepts may align with     * instruments: the type of policy instrument the concept refers to"},{"path":"/reference/calculate_degrees.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"calculate_degrees — calculate_degrees","text":"function returns dataframe entitled \"node_measures\" calculated values well original data. function return store following output dataframe values, need insert following code function script:","code":"* node_measures_name_period <- calculate_degrees(edgelist, nodelist)"},{"path":"/reference/calculate_degrees.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"calculate_degrees — calculate_degrees","text":"concept (node) map, function calculates:   weighted equivalents","code":"* degree (also called centrality): the number of unique relations/edges    by which the concept/node is connected to others (unweighted)    * indegree: the number of relations/edges feeding into a concept/node    * outdegree: the number of relations/edges feeding out of a concept/node    * the goal-orientation (go): (indegree-outdegree)/degree * weighted degree (also called saliency): the number of relations/edges      by which the concept/node is connected to others taking into account      the weight of the relations.    * indegree: the number of relations/edges feeding into a concept/node taking      into account their weight (sum of weights of all ingoing relations)    * outdegree: the number of relations/edges feeding out of a concept/node      taking into account their weight(sum of weights of all outgoing relations)    * the weighted goal-orientation (gow): (W indegree - W outdegree)/W degree"},{"path":"/reference/evaluation_step.html","id":null,"dir":"Reference","previous_headings":"","what":"Conduct the evaluation analysis — evaluation_step","title":"Conduct the evaluation analysis — evaluation_step","text":"function used determine extent nodes (concepts) CM considered positive (supported), negative (supported) ambiguous (positive negative consequences) derived argumentation map. determines evaluation node (cause-concept) analysing outgoing relations (consequent paths) taking account initial value (positive, negative, ambiguous) nodes consequent path (effect-concepts) sign (positive, negative, non-existent) relation node (cause-concept) nodes consequent paths (effect-concepts). node (cause-concept) positively linked consequent node (effect-concept) valued positively (contributes positively b b seen positive thing); logically node (cause-concept) also regarded positive. negative relation positive consequent node (effect-concept) (diminishes b, b seen positive thing) logically leads conclusion node (cause-concept) valued negatively. negative relation negatively valued node (effect-concept) suggest cause-concept positive. function takes dyads nodes (cause effect-concept) determines value cause-concepts. nodes may multiple consequent paths, may lead different conclusions value cause-concept, function needs iterated number times reach balance derive accurate evaluation nodes takes account relations map. cyclical maps, possible balance may reached propose setting diameter map maximum number iterations","code":""},{"path":"/reference/evaluation_step.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conduct the evaluation analysis — evaluation_step","text":"","code":"evaluation_step(edgelist, nodelist)"},{"path":"/reference/evaluation_step.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conduct the evaluation analysis — evaluation_step","text":"edgelist edgelist nodelist nodelist, want add evaluation dataframe basic CM measures calculated , sure use 'node_measures' list returned running calculate_degrees function.","code":""},{"path":"/reference/evaluation_step.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conduct the evaluation analysis — evaluation_step","text":"Returns list resulting edgelist nodelist","code":""},{"path":"/reference/evaluation_step.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conduct the evaluation analysis — evaluation_step","text":"","code":"# INCOMPLETE # Load the data data(\"edgelist\") #> Warning: data set 'edgelist' not found data(\"nodelist\") #> Warning: data set 'nodelist' not found  # Run the evaluation analysis"},{"path":"/reference/instrument_support.html","id":null,"dir":"Reference","previous_headings":"","what":"Instrument Support — instrument_support","title":"Instrument Support — instrument_support","text":"Calculates extent cognitive map signals support certain types policy instruments. specifically, determines saliency concepts classified type policy instrument valued positively determined via evaluate_concepts function. able run function, functions calculate-degrees evaluate_concepts  run first. Also nodelist (node_measures) list function takes, needs contain column name 'instruments' concept noted type policy instrument represents. concept refer policy instrument, cell left empty. researcher can use typology policy instruments relevant research.","code":""},{"path":"/reference/instrument_support.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instrument Support — instrument_support","text":"","code":"instrument_support(node_measures, instruments)"},{"path":"/reference/instrument_support.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instrument Support — instrument_support","text":"node_measures object class \"dataframe\" including measures returned running functions calculate_degrees & evaluate_concepts, well column title \"instruments\" concepts classified belonging pre-determined set policy instrument type. concept refer policy instrument, cell left empty. instruments object class \"vector\" containing types policy instruments occur node_measures list. derive vector run following code: \"instruments <- unique(node_measures$instruments) #deriving instrument-types node_measures dataframe instruments <- na.omit(instruments) #omitting empty cells (NULL category) analysis\"","code":""},{"path":"/reference/instrument_support.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instrument Support — instrument_support","text":"Returns object class \"dataframe\" additional columns instrument types column titles saliency scores concepts evaluated positively belong categories.","code":""},{"path":"/reference/instrument_support.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Instrument Support — instrument_support","text":"","code":"\"instruments <- base::unique(rutte_p2_node_measures$instruments) #deriving all instrument-types from the node_measures dataframe instruments <- base::na.omit(instruments) #omitting the empty cells (NULL category) from the analysis\" #> [1] \"instruments <- base::unique(rutte_p2_node_measures$instruments) #deriving all instrument-types\\nfrom the node_measures dataframe\\ninstruments <- base::na.omit(instruments) #omitting the empty cells (NULL category)\\nfrom the analysis\" rutte_p2_node_measures <- instrument_support(rutte_p2_node_measures, instruments) #> Error in instrument_support(rutte_p2_node_measures, instruments): object 'instruments' not found"},{"path":"/reference/paradigm_support.html","id":null,"dir":"Reference","previous_headings":"","what":"Paradigm Support\r\nCalculates to what extent the cognitive map signals support for a set of two\r\ncommensurable policy paradigms. More specifically, it determines the saliency of all\r\nconcepts classified as aligning with one of the two paradigms which are valued\r\npositively as determined via the evaluate_concepts function. As incommensurability\r\nsuggests that there is a zero-sum relation between the paradigms, negative valued\r\nconcepts belonging to paradigm a will be interpreted as support for paradigm b.\r\nAs such the function lists the saliency value of negatively valued concepts as\r\na positive score for the rival paradigm.\r\nTo be able to run this function, the functions calculate-degrees AND\r\nevaluate_concepts should have been run first. Also the nodelist (node_measures)\r\nlist this function takes needs to contain a column with the name 'paradigms'\r\nin which for each concept it is noted with which of the two paradigms it aligns.\r\nIf a concept does speak to either of the rival paradigms, the cell should be\r\nleft empty.\r\nThe researcher can use any rivaling set of paradigms that is relevant to\r\ntheir research as long as no more or less than two are included. — paradigm_support","title":"Paradigm Support\r\nCalculates to what extent the cognitive map signals support for a set of two\r\ncommensurable policy paradigms. More specifically, it determines the saliency of all\r\nconcepts classified as aligning with one of the two paradigms which are valued\r\npositively as determined via the evaluate_concepts function. As incommensurability\r\nsuggests that there is a zero-sum relation between the paradigms, negative valued\r\nconcepts belonging to paradigm a will be interpreted as support for paradigm b.\r\nAs such the function lists the saliency value of negatively valued concepts as\r\na positive score for the rival paradigm.\r\nTo be able to run this function, the functions calculate-degrees AND\r\nevaluate_concepts should have been run first. Also the nodelist (node_measures)\r\nlist this function takes needs to contain a column with the name 'paradigms'\r\nin which for each concept it is noted with which of the two paradigms it aligns.\r\nIf a concept does speak to either of the rival paradigms, the cell should be\r\nleft empty.\r\nThe researcher can use any rivaling set of paradigms that is relevant to\r\ntheir research as long as no more or less than two are included. — paradigm_support","text":"Paradigm Support Calculates extent cognitive map signals support set two commensurable policy paradigms. specifically, determines saliency concepts classified aligning one two paradigms valued positively determined via evaluate_concepts function. incommensurability suggests zero-sum relation paradigms, negative valued concepts belonging paradigm interpreted support paradigm b. function lists saliency value negatively valued concepts positive score rival paradigm. able run function, functions calculate-degrees evaluate_concepts run first. Also nodelist (node_measures) list function takes needs contain column name 'paradigms' concept noted two paradigms aligns. concept speak either rival paradigms, cell left empty. researcher can use rivaling set paradigms relevant research long less two included.","code":""},{"path":"/reference/paradigm_support.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Paradigm Support\r\nCalculates to what extent the cognitive map signals support for a set of two\r\ncommensurable policy paradigms. More specifically, it determines the saliency of all\r\nconcepts classified as aligning with one of the two paradigms which are valued\r\npositively as determined via the evaluate_concepts function. As incommensurability\r\nsuggests that there is a zero-sum relation between the paradigms, negative valued\r\nconcepts belonging to paradigm a will be interpreted as support for paradigm b.\r\nAs such the function lists the saliency value of negatively valued concepts as\r\na positive score for the rival paradigm.\r\nTo be able to run this function, the functions calculate-degrees AND\r\nevaluate_concepts should have been run first. Also the nodelist (node_measures)\r\nlist this function takes needs to contain a column with the name 'paradigms'\r\nin which for each concept it is noted with which of the two paradigms it aligns.\r\nIf a concept does speak to either of the rival paradigms, the cell should be\r\nleft empty.\r\nThe researcher can use any rivaling set of paradigms that is relevant to\r\ntheir research as long as no more or less than two are included. — paradigm_support","text":"","code":"paradigm_support(node_measures, paradigm_a, paradigm_b)"},{"path":"/reference/paradigm_support.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Paradigm Support\r\nCalculates to what extent the cognitive map signals support for a set of two\r\ncommensurable policy paradigms. More specifically, it determines the saliency of all\r\nconcepts classified as aligning with one of the two paradigms which are valued\r\npositively as determined via the evaluate_concepts function. As incommensurability\r\nsuggests that there is a zero-sum relation between the paradigms, negative valued\r\nconcepts belonging to paradigm a will be interpreted as support for paradigm b.\r\nAs such the function lists the saliency value of negatively valued concepts as\r\na positive score for the rival paradigm.\r\nTo be able to run this function, the functions calculate-degrees AND\r\nevaluate_concepts should have been run first. Also the nodelist (node_measures)\r\nlist this function takes needs to contain a column with the name 'paradigms'\r\nin which for each concept it is noted with which of the two paradigms it aligns.\r\nIf a concept does speak to either of the rival paradigms, the cell should be\r\nleft empty.\r\nThe researcher can use any rivaling set of paradigms that is relevant to\r\ntheir research as long as no more or less than two are included. — paradigm_support","text":"node_measures object class \"dataframe\" including measures returned running functions calculate_degrees & evaluate_concepts, well column title \"paradigms\" concepts classified belonging set two pre-determined paradigms. concept refer either paradigm, cell left empty. paradigm_a object class \"character string\" / first name paradigm occurs node_measures dataframe. paradigm_b object class \"character string\" / first name paradigm occurs node_measures dataframe. derive exact names paradigms appear node_measures dataframe, run following code: \"paradigms <- unique(node_measures$paradigms) #deriving names two paradigms node_measures dataframe paradigms <- na.omit(paradigms) #omitting empty cells (NULL category) analysis\"","code":""},{"path":"/reference/paradigm_support.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Paradigm Support\r\nCalculates to what extent the cognitive map signals support for a set of two\r\ncommensurable policy paradigms. More specifically, it determines the saliency of all\r\nconcepts classified as aligning with one of the two paradigms which are valued\r\npositively as determined via the evaluate_concepts function. As incommensurability\r\nsuggests that there is a zero-sum relation between the paradigms, negative valued\r\nconcepts belonging to paradigm a will be interpreted as support for paradigm b.\r\nAs such the function lists the saliency value of negatively valued concepts as\r\na positive score for the rival paradigm.\r\nTo be able to run this function, the functions calculate-degrees AND\r\nevaluate_concepts should have been run first. Also the nodelist (node_measures)\r\nlist this function takes needs to contain a column with the name 'paradigms'\r\nin which for each concept it is noted with which of the two paradigms it aligns.\r\nIf a concept does speak to either of the rival paradigms, the cell should be\r\nleft empty.\r\nThe researcher can use any rivaling set of paradigms that is relevant to\r\ntheir research as long as no more or less than two are included. — paradigm_support","text":"Returns object class \"dataframe\" additional columns paradigms column titles saliency scores concepts indicate positive stance towards paradigm.","code":""},{"path":"/reference/paradigm_support.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Paradigm Support\r\nCalculates to what extent the cognitive map signals support for a set of two\r\ncommensurable policy paradigms. More specifically, it determines the saliency of all\r\nconcepts classified as aligning with one of the two paradigms which are valued\r\npositively as determined via the evaluate_concepts function. As incommensurability\r\nsuggests that there is a zero-sum relation between the paradigms, negative valued\r\nconcepts belonging to paradigm a will be interpreted as support for paradigm b.\r\nAs such the function lists the saliency value of negatively valued concepts as\r\na positive score for the rival paradigm.\r\nTo be able to run this function, the functions calculate-degrees AND\r\nevaluate_concepts should have been run first. Also the nodelist (node_measures)\r\nlist this function takes needs to contain a column with the name 'paradigms'\r\nin which for each concept it is noted with which of the two paradigms it aligns.\r\nIf a concept does speak to either of the rival paradigms, the cell should be\r\nleft empty.\r\nThe researcher can use any rivaling set of paradigms that is relevant to\r\ntheir research as long as no more or less than two are included. — paradigm_support","text":"","code":"\"paradigms <- base::unique(rutte_p2_node_measures$paradigms) #deriving all instrument-types from the node_measures dataframe paradigms <- base::na.omit(paradigms) #omitting the empty cells (NULL category) from the analysis\" #> [1] \"paradigms <- base::unique(rutte_p2_node_measures$paradigms) #deriving all instrument-types\\nfrom the node_measures dataframe\\nparadigms <- base::na.omit(paradigms) #omitting the empty cells (NULL category)\\nfrom the analysis\" rutte_p2_node_measures <- paradigm_support(rutte_p2_node_measures, paradigm_a, paradigm_b) #> Error in dplyr::case_when(node_measures$paradigms == paradigm_a & node_measures$val_run1 >     0 ~ node_measures$w_degree, node_measures$paradigms == paradigm_b &     node_measures$val_run1 < 0 ~ node_measures$w_degree): Failed to evaluate the left-hand side of formula 1. #> Caused by error: #> ! object 'rutte_p2_node_measures' not found"},{"path":"/reference/select_speaker_period_make_lists.html","id":null,"dir":"Reference","previous_headings":"","what":"select_speaker_period_make_lists — select_speaker_period_make_lists","title":"select_speaker_period_make_lists — select_speaker_period_make_lists","text":"helper function select particular set edges & nodes bigger edgelist sumvalue_weighted_edges_leaders nodelist nodes_leaders_idecointval part H2020 Transcrisis research project F..W.J. van Esch (Van Esch etal 2018). database made public later date. select edges (speaker)name period function returns accompanying edgelist nodelist. Enter variables \" \", \"eind\" refers end date. using function, can name store created node edgelist reflecting content using codes: name_period_nodelist <- select_speaker_period_make_lists (\"name\", \"start\", \"eind\")[1] name_period_edgelist <- select_speaker_period_make_lists (\"name\", \"start\", \"eind\")[2]","code":""},{"path":"/reference/select_speaker_period_make_lists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"select_speaker_period_make_lists — select_speaker_period_make_lists","text":"","code":"select_speaker_period_make_lists(name, start, eind)"},{"path":"/reference/select_speaker_period_make_lists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"select_speaker_period_make_lists — select_speaker_period_make_lists","text":"name Name leader actor start start period draw edges nodes eind end period draw edges nodes","code":""},{"path":"/reference/select_speaker_period_make_lists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"select_speaker_period_make_lists — select_speaker_period_make_lists","text":"two data frames: one nodelist categorisations nodes intrinsic value (positive/negative concept) edgelist weight edge value (pos/neg/zero) metadata","code":""},{"path":"/reference/select_speaker_period_make_lists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"select_speaker_period_make_lists — select_speaker_period_make_lists","text":"","code":"x #> Error in eval(expr, envir, enclos): object 'x' not found"},{"path":"/reference/set_iterations.html","id":null,"dir":"Reference","previous_headings":"","what":"Set Iterations\r\nHelper function. Calculates the maximum number of iterations that the\r\nevaluate_concepts function needs to run in the for-loop to arrive at the\r\ncorrect evaluation of the concepts.\r\nThe maximum number of iterations is equal to the diameter of the CM. — set_iterations","title":"Set Iterations\r\nHelper function. Calculates the maximum number of iterations that the\r\nevaluate_concepts function needs to run in the for-loop to arrive at the\r\ncorrect evaluation of the concepts.\r\nThe maximum number of iterations is equal to the diameter of the CM. — set_iterations","text":"Set Iterations Helper function. Calculates maximum number iterations evaluate_concepts function needs run -loop arrive correct evaluation concepts. maximum number iterations equal diameter CM.","code":""},{"path":"/reference/set_iterations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set Iterations\r\nHelper function. Calculates the maximum number of iterations that the\r\nevaluate_concepts function needs to run in the for-loop to arrive at the\r\ncorrect evaluation of the concepts.\r\nThe maximum number of iterations is equal to the diameter of the CM. — set_iterations","text":"","code":"set_iterations(edgelist, nodelist)"},{"path":"/reference/set_iterations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set Iterations\r\nHelper function. Calculates the maximum number of iterations that the\r\nevaluate_concepts function needs to run in the for-loop to arrive at the\r\ncorrect evaluation of the concepts.\r\nThe maximum number of iterations is equal to the diameter of the CM. — set_iterations","text":"edgelist edgelist nodelist nodelist","code":""},{"path":"/reference/set_iterations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set Iterations\r\nHelper function. Calculates the maximum number of iterations that the\r\nevaluate_concepts function needs to run in the for-loop to arrive at the\r\ncorrect evaluation of the concepts.\r\nThe maximum number of iterations is equal to the diameter of the CM. — set_iterations","text":"Returns vector maximum number iterations","code":""},{"path":"/reference/set_iterations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set Iterations\r\nHelper function. Calculates the maximum number of iterations that the\r\nevaluate_concepts function needs to run in the for-loop to arrive at the\r\ncorrect evaluation of the concepts.\r\nThe maximum number of iterations is equal to the diameter of the CM. — set_iterations","text":"","code":"set_iterations(rutte_p2_edgelist, rutte_p2_nodelist) #> [1] 5"}]
